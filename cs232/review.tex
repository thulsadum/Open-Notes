\documentclass[12pt]{article}
\textwidth = 6.7 in
\textheight = 9.2 in
\oddsidemargin = 0.0 in
\evensidemargin = 0.0 in
\topmargin = 0.2 in
\headheight = 0.0 in
\headsep = 0.0 in
\parskip = 0.2in
\parindent = 0.0in

% ***********************************************************
% *********************** HEADER  ***************************
% ***********************************************************

\usepackage{amsmath} % AMS Math Package
\usepackage{amsthm} % Theorem Formatting
\usepackage{amssymb}	% Math symbols such as \mathbb
\usepackage{graphicx} % Allows for eps images
\usepackage{multicol} % Allows for multiple columns
\usepackage[dvips,letterpaper,margin=0.75in,bottom=0.5in]{geometry}
 % Sets margins and page size
\pagestyle{empty} % Removes page numbers
\makeatletter % Need for anything that contains an @ command 
\renewcommand{\maketitle} % Redefine maketitle to conserve space
{ \begingroup \vskip 10pt \begin{center} \large {\bf \@title}
p	\vskip 10pt \large \@author \hskip 20pt \@date \end{center}
  \vskip 10pt \endgroup \setcounter{footnote}{0} }
\makeatother % End of region containing @ commands
\renewcommand{\labelenumi}{(\alph{enumi})} % Use letters for enumerate
% \DeclareMathOperator{\Sample}{Sample}
\let\vaccent=\v % rename builtin command \v{} to \vaccent{}
\renewcommand{\v}[1]{\ensuremath{\mathbf{#1}}} % for vectors
\newcommand{\gv}[1]{\ensuremath{\mbox{\boldmath$ #1 $}}} 
% for vectors of Greek letters
\newcommand{\uv}[1]{\ensuremath{\mathbf{\hat{#1}}}} % for unit vector
\newcommand{\abs}[1]{\left| #1 \right|} % for absolute value
\newcommand{\avg}[1]{\left< #1 \right>} % for average
\let\underdot=\d % rename builtin command \d{} to \underdot{}
\renewcommand{\d}[2]{\frac{d #1}{d #2}} % for derivatives
\newcommand{\dd}[2]{\frac{d^2 #1}{d #2^2}} % for double derivatives
\newcommand{\pd}[2]{\frac{\partial #1}{\partial #2}} 
% for partial derivatives
\newcommand{\pdd}[2]{\frac{\partial^2 #1}{\partial #2^2}} 
% for double partial derivatives
\newcommand{\pdc}[3]{\left( \frac{\partial #1}{\partial #2}
 \right)_{#3}} % for thermodynamic partial derivatives
\newcommand{\ket}[1]{\left| #1 \right>} % for Dirac bras
\newcommand{\bra}[1]{\left< #1 \right|} % for Dirac kets
\newcommand{\braket}[2]{\left< #1 \vphantom{#2} \right|
 \left. #2 \vphantom{#1} \right>} % for Dirac brackets
\newcommand{\matrixel}[3]{\left< #1 \vphantom{#2#3} \right|
 #2 \left| #3 \vphantom{#1#2} \right>} % for Dirac matrix elements
\newcommand{\grad}[1]{\gv{\nabla} #1} % for gradient
\let\divsymb=\div % rename builtin command \div to \divsymb
\renewcommand{\div}[1]{\gv{\nabla} \cdot #1} % for divergence
\newcommand{\curl}[1]{\gv{\nabla} \times #1} % for curl
\let\baraccent=\= % rename builtin command \= to \baraccent
\renewcommand{\=}[1]{\stackrel{#1}{=}} % for putting numbers above =
\newtheorem{prop}{Proposition}
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\theoremstyle{definition}
\newtheorem{dfn}{Definition}
\theoremstyle{remark}
\newtheorem*{rmk}{Remark}
% \def\rmdefault{bch} % Use Charter for main text font.

% ***********************************************************
% ********************** END HEADER *************************
% ***********************************************************
% =========================================================
\begin{document}

\begin{center}
  {\LARGE
    \textbf{CS232 Review}\\
  }
  \begin{enumerate}
  \item Caches
    \begin{enumerate}
    \item LRU: least recently used data, often used or approximated to
      decide what to kick out of the cache
    \item
      Spacial Locality: Things near what was just used tend to get used
      again.\\
      Temporal Locality: Things that were just used, tend to get reused.
    \item Associatity: Relates how addresses get mapped inside of
      the cache to the number of sets n. (Direct Map equal n sets for
      n addresses, Fully associative 1 set for n addresses)
    \item Write-back: Writing is done only to the cache. A modified
      cache block is ``written'' back into higher memory just before
      it is stored. (requires a dirty bit to denote that it has been
      written to)
    \item Multilevel caches: A cache that utilized 2 or more separate
      caches to store information. Typically the lower caches are
      small/fast/expensive where as the higher caches are
      large/fast/cheap.\\
      Note: If one can ensure almost certain hits in the higher caches
      and relatively good rates in the lower caches this greatly
      increases speed.
    \item Computing cache size, bits, block offset, index, tag, and associatity
      \begin{enumerate}
      \item N-Way associative cache has N blocks per set. Thus
        address $\rightarrow$ cache address is given by (= denotes
        number of bits in the bitstring at that point dedicated.
        \begin{equation}
          |Tag=m-s-o|Index=s|offset=o|, m = addressSize
        \end{equation}
        \begin{equation}
          |t = m-o-s | s = lg(\frac{size}{blockSize\cdot N})|o = lg(\frac{blockSize}{byte})|
        \end{equation}
      \end{enumerate}
    \item Calculating cache performance and Average Memory Acess Time (AMAT) calculations.
      \begin{enumerate}
      \item :
        \begin{equation}
          \label{eq: AMAT}
         AMAT = HitTime + (MissRate * Miss) 
        \end{equation}
        \begin{equation}
          MemoryStallCycles = MemoryAccesses * MissRate * Miss penalty
        \end{equation}
      \end{enumerate}
    \item Memory access pattern and linearizing array access: 
    \item Memory access pattern analysis: Look for temperal and
      spacial locaility. Calculate mis-rates and how to maximize
      locality. (Blocking/ Tiling)
    \end{enumerate}
  \item Cache-Aware programming
    \begin{enumerate}
    \item Hardware stream/stride pre-fetching
    \item When to software pre-fetch
    \item Blocking/ Tiling
    \end{enumerate}
  \item Virtual Memory (VM):
    \begin{enumerate}
    \item Indirection: Adding an intermediate interface that controls endpoints
    \item Use of indirection in VM: Virtual Memory $\rightarrow$ OS
      $\rightarrow$ physical memory.This eliminates the need for
      explicit overlaying in programs.
    \item Advantages of VM.
      \begin{enumerate}
      \item Larger than memory processes: We can store ``memory'' on
        disk via paging. Also because its virtual we can say we have
        ``n'' bits of mem but only have to allocate as much as needed.
      \item Identical/Conflicting address mapping: 2 programs can both
        map to the same address because the OS/PageTable deals with
        actual mapping. i.e. sure you can have $0x4004$ (hands you $0xff0f00$)
      \item Sand-boxing processes: The page table has permission bits
        that tells the OS who can touch the cookie jar.
      \item Controlled sharing between processes: If two addresses
        need to share, it can be done under adult(OS) super vision
        because of the page table's permission bits.
      \end{enumerate}
    \item Page table: Look up table that maps virtual to physical memory
    \item Translation look-aside buffer (TLB): Looking up the page
      table translations sucks....so we cache it...aka TLB 
    \item Hierarchical page table: Page Directories $\rightarrow$ Page
      Entry $\rightarrow$ Page Table $\rightarrow$ Address . (note
      saves memory because not all Entries and Directories are
      filled.\\
      P.S. page tables should be page sizes so they themselves can be
      looked up easily....
    \item Page faults(and its affect on virtual memory design): Miss
      in the TLB, (resulting in memory seak for page). Miss in the
      cache to get page/addresses. ew....  
    \end{enumerate}
  \item Hard Disks
    \begin{enumerate}
    \item Platter: Cyclinder that houses magnetic particles organized
      in tracks:
    \item Head: Reads/Writes magnetics particles (moves by arm)
    \item Track: Circular collection of sectors
    \item Sector: Partition of Track where data is actually stored
    \item 
      \begin{equation}
        readWriteTime = Seek+RotDely +sectorRead\cdot sectors
      \end{equation}

    \item Random vs Sequential read/write performance
    \item Solid state disks (SSD): Flash memory based, everything but
      random writes it very fast. (writes are slow due to having to
      clear the whole block before to write)
    \end{enumerate}
    \begin{enumerate}
    \item Error Correcting Codes
      \begin{enumerate}
      \item Error detection vs. Error correction:
        \begin{enumerate}
        \item Error Detection is the ability to detect that somehow a
          bit (or more) has been flipped.
        \item Error Correction is the ability to detect an error has
          occurred and guess what it might have been before being flipped.
        \item Relationship: Error Detection is achievable with fewer
          bits and can be done to a further level of error (more bits
          flipped) but does not correct. Correction gives up the
          ability to detect as far but adds the ability to guess
          initial states.
        \end{enumerate}
      \item Parity: Extra bit that is the result of xor the bitstring
        (odd or even). Parity is recomputed when reading Ram and
        checked. If $P_{stored} \neq P_{computed}$ an error has occured.
      \item Hamming distance: Minimum path of states to no longer
        detect/correct errors.
      \item SECDED: Single-bit Error Correction, Double-bit Error
        Detection. Standard in ECC protect SDRAM.
      \end{enumerate}
    \item Writing code to analyze cache with a hardware pre-fetcher
      \begin{enumerate}
      \item Needs to loop such that the stride can't be predicted by
        prefecter (link list is a good canidate)
      \end{enumerate}
    \end{enumerate}
  \end{enumerate}
    
\end{center}
\end{document}
% LocalWords:  LRU Associatity associatity
