#+LaTeX_HEADER: \usepackage{header}

Diff Eq Notes

* Initial Definitions
  - Definition:
    - DE is an equation that describes the properties of an unkown
    function(s)

  - Ordinary DE:
    - describes functions of 1 variable

  - Partial DE:
    - describes multivariable functions

  - Notation:
    - independent variable: y
    - dependent variable: t
* Operator Notation
  Definition:
  $\frac{d^n}{dt^n} = D^n \rightarrow f^{(n)} = D^n(f)$
* Stability
** Definition
   1) Stability $\equiv$ a system in which long term behvaior does not
      depend within some variation on initial conditions
   2) For Linear D.E. y is Stable iff:
    \begin{equation}
    \lim_{t\rightarrow \infty} y_h = 0 \pm \epsilon
    \end{equation}
   3) For S.O.L.E
      1) Stable iff either of the equivalent statments is true:
	 1) $Re(r) < 0$
	 2) $a,b,c >0$ or $a,b,c <0$
* Initial Value Problems
  \begin{equation}
  IVP = \left \{
  \begin{array}{lr}
  DE\\
  y = C_1\\
  \vdots\\
  y^{(n)} = C_n
  \end{array}
  \right.
  \end{equation}
 
* Seperable DE
** Definition   
*** Form
    \begin{equation}
    \d{y}{t}=f(y)g(t)
    \end{equation}
*** Solution
    1) Let DE be $\d{y}{t}=f(y)g(t)$
    2) Seperating terms: $\frac{dt}{f(y)}\d{y}{t}=\frac{dt}{f(y)}f(y)g(t) \implies \frac{dy}{f(y)}=g(t)dt$
       1) If $f(y)^{-1}$ is not defined from some t, solve outside of
	  that range and consider those t separately
    3) Integrate both sides: $\int \frac{dy}{f(y)}=\int g(t)dt$
    4) If possible solve for $y(t)$
* Homogenous Equations
** Form
   \begin{equation}
   \d{y}{t}=f(\frac{y}{t})
   \end{equation}
** Technique for Solving:
   1) Let $v=\frac{y}{t} \implies y=vt$
   2) Change of variable: $y'=v't+v \implies v't+v=f(v)$
   3) Moving $v$ to left side: $t\d{v}{t}=f(v)-v = g(v)$
   4) Seperating: $\frac{dv}{g(v)}=\frac{dt}{t}$
   5) Solve using Seperable D.E. techniques
* Exact Equations
** Form
   \begin{equation}
   \pd{}{t}\Psi(f(t),y(t)) = \pd{\Psi}{f}\d{f}{t} + \pd{\Psi}{y}\d{y}{t}
   \end{equation}
** Technique for Solving:
   1) Suppose DE is of the form: $M(x,y) + N(x,y) y_x = 0$
   2) If M_y = N_x, then DE is an Exact Eq, solve for $\Psi(x,y) = \Psi( f(x), y(x))$
* Autonomous Equations
** Form
   \begin{equation}
   y'=f(y)
   \end{equation}
** Anaylsis
*** Differentiation Fields
* Linear Diff Equations
  Definition: For an operator,L, the DE: L(y) = 0 is linear iff:
  - L(y_1+y_1) = L(y_1)+L(y_2)
  - L(cy) = cL(y)

** First Order Linear Eq
*** Form
    \begin{equation}
    y' + p(t)y = f(t)
    \end{equation}
*** Solving using Integration Factors
    1) Let \mu be a mult factor s.t. $\mu y' + \mu'y=g(t) \implies [\mu(t) y(t)]'= g(t)$
    2) Thus $\mu'=\mu p(t) \implies \frac{d\mu}{\mu}=p(t)dt \implies
       \mu = e^{\int p(t)dt }$
    3) Therfore
       \begin{equation}
       y(t)e^{\int p(t)dt}=\int g(t)dt
       \end{equation} $\square$
*** Bernoulli's equations
**** Form
     \begin{equation}
     y'+p(t)y=q(t)y^n, n\in \mathbb{Z}
     \end{equation}
**** Solution
     1) Let $v=y^{2-n} \implies v'=(1-n)y^{-n}y'$
     2) Thus $y'=\frac{v'}{1-n}$ and $y = y^n v$
     3) Subsituting in Bernoulli equation: $\frac{v'}{1-n}y^n+p(t)y^nv=q(t)y^n$
     4) Moving into standard form: 
       	\begin{equation}
       	v'+(1-n)p(t)v=(1-n)q(t)
       	\end{equation}
     5) Solve using Integration Factors $\square$
*** Picard Iteration
**** Integral Equations
     Suppose $f$ is continous, then a function $y=\Phi(t)$
     solves the IVP iff $y=\Phi(t)$ solves the corresponding integral equation:
     \begin{equation}
     y(t)=y_0+\int_{t_0}^t f(s,y(s))ds
     \end{equation}
**** Idea
     1) Let $f(t) = \d{y}{t}$
     1) Construct a sequence of functions $\{g_n(t) : n \geq 0, n\in \mathbb{Z}\}$ that converges to soln:
       	1) $y_0(t) = y_0$
       	3) $y_{n+1}(t)=y_0+ \int_{t_0}^tf(s,y_n(t))ds$
*** Lipsichitz Condition
    1) For $f(t,y) \in \mathbb{R}$, f is Lipsichitz iff $\exists L\in \mathbb{R}$:
       \begin{equation}
       \abs{f(t_1,y_1)-f(t_2,y_2)} \leq L\cdot \abs{(y_1-y_2)}
       \end{equation}
    2) If $\Delta y \neq 0$ then this can be thought of as:
       \begin{equation}
       \abs{\frac{\Delta f}{\Delta y}} \leq L
       \end{equation}
    3) _Lemma_: if $f_y$ is bounded then f is Lipsichitz
*** Uniform Convergence (U.C.)
**** Definition:
     A sequence of functions $\{f_n(t) : n\geq 0 ; n\in\mathbb{Z}\}$
     defined on the inverval $I$ _uniformially converges_ to $f(t)$ iff
     $\forall t > 0, \exists N\in \mathbb{Z}$ s.t. $\abs{f_n(t)-f(t)}
     < \epsilon$ everywhere on I $\forall n > N$
**** 
     _Theorem_: Given $\f_n(t)$ is continuous on I, if
     $\lim_{n\rightarrow \infty}{f_n(t)} \rightarrow f(t)$ with U.C, then:
       	1. $f$ is continuous
       	2. If $f_n$ is differtiable, then $f$ is differtiable and $f'_n$
           U.C. to $f'$
       	3. The limit is communitive with respect to integration
	  \begin{equation}
	  \lim_{n\rightarrow \infty}\int_I f_n(t)dt = \int_I \lim_{n\rightarrow \infty} f_n(t) dt
	  \end{equation}
**** Weirstress M Test
     _Theorem_: 
     - If $\forall n \in I, \abs{f_n(t)} \leq M_n$ and if $\sum_{n=0}^\infty M_n< L$ for some $L\in \mathbb{R}$, 
     - Then $\sum_{n=0}^\infty f_n(t)$ Converges Uniformially on I
*** Existence Theorem
    1. _Claim_: 
       1. If:
	  1. $f(y)$ is continous
	  2. $f$ is Lipsichitz w.r.t. $y \in R\equiv \{\(t,y) :
             \abs{t-t_0}\leq T$ and $\abs{y-y_0} \leq k\}$
	  4. $\sum_{k=1}^\infty [y_k(t)-y_{k-1}(t)]$ converges uniformially
       2. Then: $\exists$ a solution to the IVP on the interval
          $\abs{t-t_0}\leq T_1=min(T,\frac{k}{m})$ where $\abs{f(t,y)} \leq M\in R$
    2. _Proof_:
       1. Converting the IVP to an I.E.: $y(t)=y_0+\int_{t_0}^t f(s,y(s))ds$
       2. Note theat: $\abs{y_k(t)-y_{k-1}(t)} \leq \frac{M}{L}
          \frac{L^n (t-t_0)^n}{n!} \leq \frac{M}{L}\frac{L^n T_1^n}{n!}$
       3. Define: $M_n\equiv\sum_{k=1}^\infty\frac{M}{L}\frac{(L T_1)^n}{n!} = \frac{M}{L}(e^{LT_1}-1)$
       4. Apply the Weirstress M Test, because $\frac{M}{L}\frac{(L
          T_1)^n}{n!}$ converges, then $\sum_{k=1}^\infty[y_k-y_{k-1}]$ converges
       5. Thus the series $\{y_n : n \geq 1\}$ converges uniformially
          on the interval.
       6. Therefore $\exists$ a solution to the IVP $\square$
*** Uniqueness Theorm
    1. _Claim_: 
       1. If $\Phi(t)$ and $\Psi(t)$ are solutions of $y'\equiv
	  f(y,t) \in R$ and if $f$ is Lipseitz w.r.t. $y\in R$
       2. Then $\abs{\Phi(t) - Psi(t)} \leq e^{L\abs{t-t_0}}
          \abs{\Phi(t_0) - \Psi(t_0)} = 0$
	  1. Because they solve the same I.V.P. $\abs{\Phi(t_0) -
             \Psi(t_0)} = 0$
       3. Equivalently: Then $\Psi(t) = \Psi(t)$
    2. _Proof_:
       1. $E\equiv \abs{\Phi(t)-\Psi(t)}^2$
	  1. Note that $E\geq 0$
       2. $\d{}{t}E=2(\Phi(t)-\Psi(t))(\Phi'(t)-\Psi'(t))$
       3. $E'\stackrel{DE}{=}2(\Phi(t)-\Psi(t))(f(t,\Phi)-f(t,\Psi))$
       4. $E'\stackrel{Lip}{\leq} 2\abs{\Phi(t)-\Psi(t)}L\abs{\Phi(t)-\Psi(t)}$
       5. Thus $E' \leq 2LE \implies E'-2LE \leq 0\implies (E(t) e^{-2Lt})' \leq 0$
	  1. Note that E' is stricly decreasing
       6. Therefore: $e^{-t}E(t)\leq e^{2Lt_0} E(t_0) \implies
          E(t)\leq e^{2L(t-t_0)}E(t_0)$
       7. Substituting: $\abs{\Phi(t)-\Psi(t)}^2 \leq e^{2L(t-t_0)} \abs{\Phi(t_0)-\Psi(t_0)}^2$
       8. Because of absolute value: $\abs{\Phi(t)-\Psi(t)} \leq e^{2L(t-t_0)} \abs{\Phi(t_0)-\Psi(t_0)}$
       9. Because they solve the same I.V.P. $\abs{\Phi(t_0) -
          \Psi(t_0)} = 0$
       10. Thus $\Phi(t)=\Psi(t) \square$
** Second Order Linear Eq
*** The Wronskian:
\begin{equation}
W(f,g)(t) = \left |
\begin{array}{cccc}
	 f_1(x) & f_2(x) & \cdots & f_n(x) \\
	 f_1'(x) & f_2'(x) & \cdots & f_n' (x)\\
	 \vdots & \vdots & \ddots & \vdots \\
	 f_1^{(n-1)}(x)& f_2^{(n-1)}(x) & \cdots & f_n^{(n-1)}(x)
\end{array} \right |,\qquad x\in I
\end{equation}

*** Existence Theorem
    1) Claim: For all D.E. there exists a $y(t)$ that satisfies it
       locally on some interval

    2) Proof:
       	1) Let $y'=v \rightarrow v'=y''$
       	2) Therefore $v'=-py'-qy=-pv-qy$ , by plugging into the DE
       	3) In matrix form:
	   \begin{equation}
	   \left [
	   \begin{array}{c}
	   y\\v
	   \end{array} \right ]'=
	   \left [
	   \begin{array}{lr}
	   0 & 1\\
	   -q & -p
	   \end{array} \right ]
	   \left [
	   \begin{array}{c}
	   y\\v
	   \end{array} \right ]
	   \end{equation}
       	4) Note that this is a linear first order matrix system which there
	   is an existence therom for
*** Uniqueness
*** Second Order Linear Homogenous Diff Eq (S.O.L.H.D.E)
**** Form
     \begin{equation}
     a(x)\dd{y}{t} + b(x)\d{y}{t} + c(x)y=0
     \end{equation}
**** Theorm: The general solution to S.O.L.H.E
     Claim: The general soln of eq1$\equiv [y''+p(t)y'+g(t)y=0]$ is:
     \begin{equation}
     y_h=c_1y_1+c_2 y_2
     \end{equation}
**** Proof:
***** Q1: 
      Given y_1 and y_2 are solutions, why is $c_1y_1+c_2y_2$ a solution
	 1) $Eq1=D^2(y)+p(t)D(y)+q(t)y=0$
	 2) $Eq1=[D^2+p(t)D+q(t)]y=0$
	 3) Let $L=[D^2+p(t)D+q(t)]\rightarrow eq1\equiv L(y)=0$
	 4) Notice the L is a linear operator and thus obeys the
	    superposition principle
	 5) Thus $y = c_1 y_1 +c_2 y_2$ is a solution $\square$
***** Q2: 
      Given 2 indepent solutions y_1 and y_2 for the DE, $\forall$ IVP and its unique solution y, $\exists (c_1,c_2)
	 \in \mathbb{C}^2$ s.t. $y=c_1y_1 + c_2y_2 \equiv \vec{y}\cdot\vec{c}$
	 
******* Sub Proof of Q2
       	Consider IVP: $y''+py'+qy=0$
       	1) Take c_1 and c_2 s.t.:
	   \begin{equation}
	   \left [
	   \begin{array}{c}
	    a\\
	    b
	   \end{array}\right ]=
	   \left [
	   \begin{array}{cc}
	   y_1&y_2\\
	   y_1'&y_2'\\
	   \end{array} \right ]_{t=t_0}
	   \left [
	   \begin{array}{c}
	   c_1\\
	   c_2
	   \end{array} \right ]}
	   \end{equation}
       	2) Notice this is only solvable iff $W(y_1,y_2)_{t=t_0}\neq 0$
       	3) _Theorem_: If u and v solve $y'' + p(t)y' + g(t)y = 0$ then
	   W(u,v)=0 for all t or W is never 0
***** Q3:
****** Abel's Identity
       1. If u,v solve the D.E. then $W'+p(t)W=0 \rightarrow ce^{-\int p(t)dt}$
       2. Alternatively: $W' +p(t)W=0 \implies W'=0 \implies W=C$
****** Finding the general solution
      Goal: The general soln is of the form $y=\vec{y}\cdot\vec{c}$
      1) Recall the matrix form of the D.E. from the Existence theorem
	 proof.
      2) Also Recall that that the equation was only solvable if
	 $W(y_1,y_2)(t_0)\neq 0$
      3) Observe that $W'=(uv'+uv'')-(u'V+u'v') =-pW$
      4) _Lemma_: if u,v are linearly dependent, then $W(u,v)=0$ on I
**** Generating Second Solution
     1) Claim: if $y_1\neq 0$ be a solution to the D.E. then,
       	\begin{equation}
       	y_2 = Cy_1\int \frac{e^{-\int p dt}}{y_1^2}
       	\end{equation}
       	and y_2 = solution independent of y_1
     2) Proof:
       	1) Consider $(\frac{y_2}{y_1})' = \frac{y_1 y_2' - y_1'y_2}{y_1^2}=\frac{W(y_1,y_2)}{y_1^2}$
       	2) Given that $W'+p(t)W=0 \implies W(t)=ce^{-\int p(t) dt}$
       	3) Thus: $\int (\frac{y_2}{y_1})'dt = C \int \frac{e^{-\int p
	   dt}}{y_1^2}$
       	4) Solving: $y_2=Cy_1\int \frac{e^{-\int p
	   dt}}{y_1^2} \square$
*** Second Order Linear Inhomogenious Diff Eq (S.O.L.I.D.E)
**** Form
     \begin{equation}
     y^{(n)}(t)+p(t)y'(t)+q(t)y=f(t)
     \end{equation}
**** General Solution
      1. _Claim_: The general soln of $y^{(n)}(t)+p(t)y'(t)+q(t)y=f(t)$ is:
	 \begin{equation}
	 y=y_h+k(t)
	 \end{equation}
	 1. $y_h = c_1y_1+c_2y_2$ is the solution to the homogenous
	    equation i.e. $f(t)=0$
	 2. Functional Offset $(k(t))$: variation or 'offset' from the homogenous equation
      2. _Proof_:
	 1. Sub-Claim: $y_h+k$ is a solution
	    1. Using Operator notation: $D^2y+pDy+qy=f \implies [D^2+pD+q](y)=f$
	    2. Let $L\equivD^2+pD+q \implies L(y)=f$
	       1. Note that L is linear
	    3. $L(y_h+k) = L(y_h+k)=L(y_h)+L(y_p)$
	    4. $L(y_h)=0,L(y_p)=f \implies L(y_h+k)=f+0 = f \square$
	 2. Sub-Claim: $\forall y_i$, if $y_i$ is a solution to the
	    S.O.L.I.D.E, then $y_i=y_h+k$
	    1. $[L(y_i)=f$ and $L(k)=f] \implies L(y_i-k) = f-f=0$
	    2. By Existence of S.O.L.H.D.E, $L(y_i-k)=0 \implies$ $y_i-k=y_h$
	    3. Thus $y_i=k+y_h \square$
**** Exponential Shift Law
     \begin{equation}
     P(D)[e^{\alpha u(t)}]=p(D+\alpha)u(t)[e^{\alpha t}]
     \end{equation}
**** Expontial-Polynomial Functional offesets
***** Form
      \begin{equation}
      ay''+by'+cy=e^{\alpha t}g(t); \alpha\in\mathbb{C}
      \end{equation}
***** Characteristic Polynomial
      \begin{equation}
      p(r)=aD^2+bD+c
      \end{equation}
      Note that the DE in Operator notation is: $[aD^2+bD+c]$
***** Finding Particular Solution for S.O.L.E
      _Theorem_:
      - Let $k$ be s.t. $(r-\alpha)^k$ are roots of $p(\alpha)$
      - Then 
       	\begin{equation}
       	y_p=\frac{t^ke^{\alpha t}}{p^{(k)}(\alpha)}
       	\end{equation}
***** Method of Undetermined Coefficents
      _Idea_: if f(t) is a comprised of strict multiplications (no division) sinusoidal,exponetials, and
      polynomials then the solution of the S.O.L.E with const
      coefficents is in terms of of the same types you began with.

      _Cases_:
      
      if $f(t)=e^{\alpha t}$ (polynomial of $deg(k+m)$), then guess
      $y_p=e^{\alpha t}\Sigma_{j=0}^k C_jt^j$
**** Annihilator Method
     1. Given: $(D^2+aD+b)y=e^{\alpha t}f(t)$, where $f(t)$ is a polynomial
     2. Attempt to multiply both sides by a Differential Operator ($G$) s.t.
	\begin{equation}
	G(e^{\alpha t}f(t)) = 0 \implies G(D^2+aD+b)y=0
	\end{equation}
     3. Notice that this is now a homogenous equation. Solve by
        finding the roots of the characteristic equation and applying
        the method of undetermined coefficents
**** Lagrange Variation of Parameters
***** Equation:
      \begin{equation}
      y_p=\int{\frac{y_1f(x)}{W(y_1,y_2)}dt}+\int{\frac{y_2f(x)}{W(y_1,y_2)}dt}
      \end{equation}
***** Derivation:
      See General Derivation
*** Foulrier Transform
*** Strum Comparison Theorem
    _Theorem_: 
    1. If:
       1. $u''+q_1(t)u=0$ and $v''+q_2v =0$
       2. $q_1>q_2$
    2. Then:
       1. $u$ vanishes as some point between $2$ zeros of $v$
** General Linear Diff Eq and Variation of Parameters
*** Form
    \begin{equation}
    y^{(n)}(x)+\sum_{k=0}^na_k(x)y^{(k)}(x)=f(x)
    \end{equation}
*** Equation:
    \begin{equation}
    \sum_{k=0}^n[y_k(x)\int{\frac{W_k(x)}{W(X)}dx}]
    \end{equation}
    $W(x)\equiv$ Wronskian determinant of the fundamental system
    and $W_i(x)\equiv$ the Wronskian determinant of the fundamental system
    with the $i-th$ column replaced by $(0,0,\ldots,f(x))$   
**** Derivation:

*** Theorem for L.D.E
    If $u(t)+iv(t)$ is a solution to the D.E. then $u(t) \wedge v(t)$
    are solutions

* First Order Systems of Linear Diff Equations with Const Coefficents
** Form
   \begin{equation}
   \vec{r}' = A\vec{r}
   \end{equation}
*** Example 1st Order
    \begin{equation}
    \vec{r}' = \left [
    \begin{array}{c}
    x' \\
    y'
    \end{array} \right ] = \left [
    \begin{array}{c}
    ax+by\\
    cx+dy
    \end{array} \right ] = \left [
    \begin{array}{cc}
    a & b\\
    c & d\\
    \end{array} \right ] \left [
    \begin{array}{c}
    x\\
    y\\
    \end{array} \right ]
    \end{equation}
** Solution
   1. Guess: $\vec{r} = \vec{a} e^{\lambda t}$, $\vec{a} \in D$
   2. Thus $\vec{r}' = \lamda \vec{a} e^{\lambda t} \implies \lambda
      \vec{a} = A \vec{a}$
   3. Factoring we get $(A-\lambda I)\vec{a} = \vec{0}$
   4. _Characteristic Polynomial_ $\equiv \abs{A-\lambda I}$
      1. For the 2-d version we get
	 \begin{equation}
	 \abs{A-\lambda I} = \lambda^2 + tr(A) + |A|
	 \end{equation}
   5. Solve for Eigen Value and Corresponding Eigen Vectors
      1. _Complete e-value_: K-Repeated Eigen value produces K linearly
	 independent eigen vectors
      2. _Incomplete e-value_: Does not produce enough
	 e-values. Solution: assume solution is:
	 \begin{equation}
	 \vec{r} = u(t)\vec{a}e^{\lambda t} + \vec{c}
	 \end{equation}
	 1. Typically $u(t)$ is a polynomial as in the $D$-1 case

** Classification
   Let $p\equiv tr(A)$ and $q\equiv |A|$

*** Theorem: Change of coordinates
    1. _Claim_: $\vec{x}' = A\vec{x} \equiv \vec{y}' = B\vec{y}
       \iff |A-\lamba I| = |B-\lamba I|$ and $(tr[A])^2 -4|A|
       \neq 0$
       1. $(tr[A])^2 -4|A| \neq 0$ excludes repeated roots
    2. _Alternate version_: $\exists$ non-singular matrix $U$ s.t. $\vec{y}=U\vec{x}$ and $B = UAU^{-1}$
       1. This is a change of cordinates
    3. _Light Proof_: Suppose $\vec{x}' = A\vec{x} \equiv \vec{y}' = B\vec{y}'$
       1. By the claim $|B-\lambda I| = |UAU^{-1} - \lambda I|$
       2. Note that $\lambda I = \lambda U U^{-1} = U\lambda I U^{-1} \implies |B -
          \lambda I| = |UAU^{-1} - U(\lambda I)U^{-1} |$
       3. Factoring $|U(A-\lambda I)U^{-1}| = |U| |A-\lambda I||U^{-1}$
       4. Using the communitive property of
          multiplication: $|U||U^{-1}||A-\lambda I| = |A-\lambda I|$
       5. Thus: $|B - \lambda I| = |A - \lambda I|$
